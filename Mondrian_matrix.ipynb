{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn import linear_model\n",
    "import sys\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils_mondrian import sample_cut, errors_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, M, lifetime_max, delta,\n",
    "          mondrian_kernel=False, mondrian_forest=False, weights_from_lifetime=None):\n",
    "    \"\"\"\n",
    "    Sweeps through Mondrian kernels with all lifetime in [0, lifetime_max]. This can be used to (1) construct a Mondrian\n",
    "    feature map with lifetime lifetime_max, to (2) find a suitable lifetime (inverse kernel width), or to (3) compare\n",
    "    Mondrian kernel to Mondrian forest across lifetimes.\n",
    "    :param X:                       training inputs\n",
    "    :param y:                       training regression targets\n",
    "    :param M:                       number of Mondrian trees\n",
    "    :param lifetime_max:            terminal lifetime\n",
    "    :param delta:                   ridge regression regularization hyperparameter\n",
    "    :param mondrian_kernel:         flag indicating whether mondrian kernel should be evaluated\n",
    "    :param mondrian_forest:         flag indicating whether mondrian forest should be evaluated\n",
    "    :param weights_from_lifetime:   lifetime at which forest and kernel learned weights should be saved\n",
    "    :return: dictionary res containing all results\n",
    "    \"\"\"\n",
    "    \n",
    "    N, D = np.shape(X)\n",
    "    history = []\n",
    "\n",
    "    if mondrian_forest or mondrian_kernel:\n",
    "        y = np.squeeze(y)\n",
    "\n",
    "        # subtract target means\n",
    "        y_mean = np.mean(y)\n",
    "        y_train = y - y_mean\n",
    "\n",
    "    # initialize sparse feature matrix\n",
    "    indptr = range(0, M * N + 1, M)\n",
    "    indices = list(range(M)) * N\n",
    "    data = np.ones(N * M) / np.sqrt(M)\n",
    "    Z_all = scipy.sparse.csr_matrix((data, indices, indptr), shape=(N, M))\n",
    "    feature_from_repetition = list(range(M))\n",
    "    C = M\n",
    "    X_bd_all = np.tile(X, (M*D,1)).reshape(M,D,N,D)\n",
    "\n",
    "    # bounding box for all datapoints used to sample first cut in each tree\n",
    "    feature_data = [np.array(range(N)) for _ in range(M)]\n",
    "    lX = np.min(X, 0)\n",
    "    uX = np.max(X, 0)\n",
    "\n",
    "    # event = tuple (time, tree, feature, dim, loc), where feature is the index of feature being split\n",
    "    events = []\n",
    "    active_features = []\n",
    "    active_features_in_tree = [[] for _ in range(M)]\n",
    "    for m in range(M):\n",
    "        cut_time, dim, loc = sample_cut(lX, uX, 0.0)\n",
    "        if cut_time < lifetime_max:\n",
    "            heapq.heappush(events, (cut_time, m, m, dim, loc))\n",
    "        active_features.append(m)\n",
    "        active_features_in_tree[m].append(m)\n",
    "\n",
    "    # iterate through birth times in increasing order\n",
    "    if mondrian_forest:\n",
    "        w_trees = [np.zeros(1) for _ in range(M)]\n",
    "        trees_y_hat_train = np.zeros((N, M))        # initialize Mondrian tree predictions and squared errors\n",
    "    if mondrian_kernel:\n",
    "        w_kernel = np.zeros(M)\n",
    "\n",
    "    while len(events) > 0:\n",
    "        (birth_time, m, c, dim, loc) = heapq.heappop(events)\n",
    "        history.append((birth_time, m, c, dim, loc))\n",
    "\n",
    "        # construct new feature\n",
    "        Xd = X[feature_data[c], dim]\n",
    "        feature_l = (feature_data[c])[Xd <= loc]\n",
    "        feature_r = (feature_data[c])[Xd  > loc]\n",
    "        feature_data.append(feature_l)\n",
    "        feature_data.append(feature_r)\n",
    "\n",
    "        active_features.remove(c)\n",
    "        active_features_in_tree[m].remove(c)\n",
    "        active_features.append(C + 0)\n",
    "        active_features.append(C + 1)\n",
    "        active_features_in_tree[m].append(C + 0)\n",
    "        active_features_in_tree[m].append(C + 1)\n",
    "\n",
    "        # move datapoints from split feature to child features\n",
    "        Z_all.indices[feature_l * M + m] = C + 0\n",
    "        Z_all.indices[feature_r * M + m] = C + 1\n",
    "        Z_all = scipy.sparse.csr_matrix((Z_all.data, Z_all.indices, Z_all.indptr), shape=(N, C + 2), copy=False)\n",
    "\n",
    "        # sample the cut for each child\n",
    "        lX_l = np.min(X[feature_l, :], axis=0)\n",
    "        uX_l = np.max(X[feature_l, :], axis=0)\n",
    "        cut_time_l, dim_l, loc_l = sample_cut(lX_l, uX_l, birth_time)\n",
    "        lX_r = np.min(X[feature_r, :], axis=0)\n",
    "        uX_r = np.max(X[feature_r, :], axis=0)\n",
    "        cut_time_r, dim_r, loc_r = sample_cut(lX_r, uX_r, birth_time)\n",
    "\n",
    "        if (loc_l is not None) and (loc_r is not None):\n",
    "            X_bd_all[m, dim, feature_l, dim] = lX_r[dim]\n",
    "            X_bd_all[m, dim, feature_r, dim] = uX_l[dim]\n",
    "\n",
    "        # add new cuts to heap\n",
    "        if cut_time_l < lifetime_max:\n",
    "            heapq.heappush(events, (cut_time_l, m, C + 0, dim_l, loc_l))\n",
    "        if cut_time_r < lifetime_max:\n",
    "            heapq.heappush(events, (cut_time_r, m, C + 1, dim_r, loc_r))\n",
    "\n",
    "        feature_from_repetition.append(m)\n",
    "        feature_from_repetition.append(m)\n",
    "        C += 2\n",
    "\n",
    "        if mondrian_forest:\n",
    "            # update Mondrian forest predictions in tree m\n",
    "            Z_train = Z_all[:N, active_features_in_tree[m]]\n",
    "            w_tree = np.linalg.solve(np.transpose(Z_train).dot(Z_train) + delta / M * np.identity(len(active_features_in_tree[m])),\n",
    "                                np.transpose(Z_train).dot(y_train))\n",
    "            if weights_from_lifetime is not None and birth_time <= weights_from_lifetime:\n",
    "                w_trees[m] = w_tree / np.sqrt(M)\n",
    "            trees_y_hat_train[:, m] = np.squeeze(Z_train.dot(w_tree))\n",
    "\n",
    "        # update Mondrian kernel predictions\n",
    "        if mondrian_kernel:\n",
    "            w_kernel = np.append(w_kernel, [w_kernel[c], w_kernel[c]])\n",
    "            w_kernel[c] = 0\n",
    "\n",
    "            clf = linear_model.SGDRegressor(alpha=delta, fit_intercept=False)\n",
    "            clf.fit(Z_all, y_train, coef_init=w_kernel)\n",
    "            w_kernel = clf.coef_\n",
    "\n",
    "    # this function returns a dictionary with all values of interest stored in it\n",
    "    \n",
    "    results = {'Z': Z_all, 'feature_from_repetition': np.array(feature_from_repetition)}\n",
    "    if mondrian_kernel:\n",
    "        y_hat_train = y_mean + Z_all.dot(w_kernel)\n",
    "    return results, X_bd_all, X, history, w_kernel, y_hat_train\n",
    "\n",
    "def evaluate(X, y, X_test, M, delta, history, w_kernel,\n",
    "             mondrian_kernel=False, mondrian_forest=False, weights_from_lifetime=None,):\n",
    "    \"\"\"\n",
    "    Sweeps through Mondrian kernels with all lifetime in [0, lifetime_max]. This can be used to (1) construct a Mondrian\n",
    "    feature map with lifetime lifetime_max, to (2) find a suitable lifetime (inverse kernel width), or to (3) compare\n",
    "    Mondrian kernel to Mondrian forest across lifetimes.\n",
    "    :param X:                       training inputs\n",
    "    :param y:                       training regression targets\n",
    "    :param X_test:                  test inputs\n",
    "    :param y_test:                  test regression targets\n",
    "    :param M:                       number of Mondrian trees\n",
    "    :param lifetime_max:            terminal lifetime\n",
    "    :param delta:                   ridge regression regularization hyperparameter\n",
    "    :param validation:              flag indicating whether a validation set should be created by halving the test set\n",
    "    :param mondrian_kernel:         flag indicating whether mondrian kernel should be evaluated\n",
    "    :param mondrian_forest:         flag indicating whether mondrian forest should be evaluated\n",
    "    :param weights_from_lifetime:   lifetime at which forest and kernel learned weights should be saved\n",
    "    :return: dictionary res containing all results\n",
    "    \"\"\"\n",
    "    N, D = np.shape(X)\n",
    "    N_test = np.shape(X_test)[0]\n",
    "    X_all = np.array(np.r_[X, X_test])\n",
    "    N_all = N + N_test\n",
    "    history = deepcopy(history)\n",
    "\n",
    "    if mondrian_forest or mondrian_kernel:\n",
    "        y = np.squeeze(y)\n",
    "\n",
    "        # subtract target means\n",
    "        y_mean = np.mean(y)\n",
    "        y_train = y - y_mean\n",
    "\n",
    "    # initialize sparse feature matrix\n",
    "    indptr = range(0, M * N_all + 1, M)\n",
    "    indices = list(range(M)) * N_all\n",
    "    data = np.ones(N_all * M) / np.sqrt(M)\n",
    "    Z_all = scipy.sparse.csr_matrix((data, indices, indptr), shape=(N_all, M))\n",
    "    C = M\n",
    "\n",
    "    # iterate through birth times in increasing order\n",
    "    if mondrian_forest:\n",
    "        w_trees = [np.zeros(1) for _ in range(M)]\n",
    "        trees_y_hat_train = np.zeros((N, M))        # initialize Mondrian tree predictions and squared errors\n",
    "        trees_y_hat_test = np.zeros((N_test, M))\n",
    "    \n",
    "    feature_data = [np.array(range(N_all)) for _ in range(M)]\n",
    "    active_features = []\n",
    "    active_features_in_tree = [[] for _ in range(M)]\n",
    "    for m in range(M):\n",
    "        active_features.append(m)\n",
    "        active_features_in_tree[m].append(m)\n",
    "\n",
    "    while len(history) > 0:\n",
    "        (birth_time, m, c, dim, loc) = history.pop(0)\n",
    "\n",
    "        # construct new feature\n",
    "        Xd = X_all[feature_data[c], dim]\n",
    "        feature_l = (feature_data[c])[Xd <= loc]\n",
    "        feature_r = (feature_data[c])[Xd  > loc]\n",
    "        feature_data.append(feature_l)\n",
    "        feature_data.append(feature_r)\n",
    "\n",
    "        active_features.remove(c)\n",
    "        active_features_in_tree[m].remove(c)\n",
    "        active_features.append(C + 0)\n",
    "        active_features.append(C + 1)\n",
    "        active_features_in_tree[m].append(C + 0)\n",
    "        active_features_in_tree[m].append(C + 1)\n",
    "\n",
    "        # move datapoints from split feature to child features\n",
    "        Z_all.indices[feature_l * M + m] = C + 0\n",
    "        Z_all.indices[feature_r * M + m] = C + 1\n",
    "        Z_all = scipy.sparse.csr_matrix((Z_all.data, Z_all.indices, Z_all.indptr), shape=(N_all, C + 2), copy=False)\n",
    "\n",
    "        C += 2\n",
    "\n",
    "        if mondrian_forest:\n",
    "            # update Mondrian forest predictions in tree m\n",
    "            Z_train = Z_all[:N, active_features_in_tree[m]]\n",
    "            Z_test = Z_all[N:, active_features_in_tree[m]]\n",
    "            w_tree = np.linalg.solve(np.transpose(Z_train).dot(Z_train) + delta / M * np.identity(len(active_features_in_tree[m])),\n",
    "                                np.transpose(Z_train).dot(y_train))\n",
    "            if weights_from_lifetime is not None and birth_time <= weights_from_lifetime:\n",
    "                w_trees[m] = w_tree / np.sqrt(M)\n",
    "            trees_y_hat_train[:, m] = np.squeeze(Z_train.dot(w_tree))\n",
    "            trees_y_hat_test[:, m] = np.squeeze(Z_test.dot(w_tree))\n",
    "\n",
    "            # update Mondrian forest error\n",
    "            y_hat_train = y_mean + np.mean(trees_y_hat_train, 1)\n",
    "            y_hat_test = y_mean + np.mean(trees_y_hat_test, 1)\n",
    "\n",
    "        # update Mondrian kernel predictions\n",
    "    \n",
    "    if mondrian_kernel:\n",
    "        Z_train = Z_all[:N]\n",
    "        Z_test = Z_all[N:]\n",
    "        y_hat_train = y_mean + Z_train.dot(w_kernel)\n",
    "        y_hat_test = y_mean + Z_test.dot(w_kernel)\n",
    "    return y_hat_train, y_hat_test\n",
    "    \n",
    "def simulate_y(x, seed = 0, noise_sig2 = 0.0001):\n",
    "    y = x[:, 0]**4 + x[:, 1]**4 + x[:, 2]**4 + x[:, 3]**4 + x[:, 4]**4\n",
    "    r_noise = np.random.RandomState(seed)\n",
    "    n = len(x)\n",
    "    noise = r_noise.randn(n, 1) * np.sqrt(noise_sig2)\n",
    "    y = y + noise[:, 0]\n",
    "    return y\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def draw(dim_in, psi_est, labels = None):\n",
    "    x = np.linspace(0, dim_in-1, dim_in)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(x, psi_est, linewidth=1.0, label = \"diag\")\n",
    "    if labels is not None:\n",
    "        plt.xticks(x, labels)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.00486733, -0.00415356, -0.02480744, ...,  0.01658599,\n",
      "        0.01656514,  0.02857366]), array([-0.00030784, -0.00125168, -0.01769588, ...,  0.01207939,\n",
      "       -0.02040708,  0.03468361]), array([ 0.05924769,  0.00123508,  0.07203502, ..., -0.01538729,\n",
      "       -0.00920862, -0.03409276]), array([-0.00632032, -0.21592102, -0.03938043, ...,  0.03942383,\n",
      "       -0.0212093 , -0.02126387]), array([-0.01922721, -0.01762063, -0.02951341, ..., -0.00741444,\n",
      "       -0.06796965, -0.03390933]), array([ 0.03862003,  0.04663896,  0.0110344 , ..., -0.00199783,\n",
      "       -0.00198503,  0.00219551]), array([0.00877959, 0.00789739, 0.02504385, ..., 0.00935919, 0.01181944,\n",
      "       0.00507523]), array([-0.04793662, -0.0014619 , -0.00583246, ..., -0.00380089,\n",
      "       -0.00123318, -0.00142037]), array([-0.00894403,  0.00410862,  0.00481744, ...,  0.00144267,\n",
      "        0.00392338,  0.01322526]), array([-0.01649974,  0.00121691, -0.01236693, ...,  0.0061248 ,\n",
      "       -0.00146234, -0.00272727])]\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "dim_in = 10\n",
    "x_train = np.random.rand(n,dim_in)*2 - 1\n",
    "y_train = simulate_y(x_train)\n",
    "\n",
    "M = 100                      # number of Mondrian trees to use\n",
    "lifetime_max = 0.05          # terminal lifetime\n",
    "weights_lifetime = 2*1e-6   # lifetime for which weights should be plotted\n",
    "delta = 0.1              # ridge regression delta\n",
    "result, X_bd_all, X, history, w_kernel, y_hat_train = train(x_train, y_train, M, lifetime_max, delta, mondrian_kernel = True,\n",
    "                            weights_from_lifetime=weights_lifetime)\n",
    "\n",
    "#y_hat_train, y_hat_test = evaluate(x_train, y_train, x_test, M, delta, history, w_kernel, mondrian_kernel = True, \n",
    "#         weights_from_lifetime=weights_lifetime)\n",
    "\n",
    "importance = []\n",
    "for dim in range(dim_in):\n",
    "    x_eval = None\n",
    "    y_eval = []\n",
    "    x_diff = []\n",
    "    for tree in range(M):\n",
    "        if sum(sum(abs(X_bd_all[tree,dim] - X))) > 0:\n",
    "            temp = X_bd_all[tree,dim] - X\n",
    "            subset = temp[:,dim] != 0\n",
    "            if x_eval is None:\n",
    "                x_eval = X_bd_all[tree,dim][subset]\n",
    "            else:\n",
    "                x_eval = np.vstack((x_eval, X_bd_all[tree,dim][subset]))\n",
    "            y_eval = y_eval + list(y_hat_train[subset])\n",
    "            x_diff = x_diff + list(temp[:,dim][subset])\n",
    "    _, y_hat_test = evaluate(x_train, y_train, x_eval, M, delta, history, w_kernel, mondrian_kernel = True, \n",
    "                            weights_from_lifetime=weights_lifetime)\n",
    "    \n",
    "    importance.append(((y_eval - y_hat_test)/x_diff))\n",
    "#importance = np.vstack(importance)\n",
    "\n",
    "print(importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
