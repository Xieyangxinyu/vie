{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQtHhn1Y7CQr"
      },
      "source": [
        "# Variable Importance Estimation\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/174JPxk6-AKrjnyqkM1dvKtthPYJu31Sd#scrollTo=FQtHhn1Y7CQr)\n",
        "\n",
        "**This is a simple and unified framework for nonlinear variable importance estimation that incorporates uncertainty in the prediction function and is compatible with a wide range of machine learning models (e.g., tree ensembles, kernel methods, neural networks, etc).**\n",
        "\n",
        "This tutorial aims to provide some exmaples to use VIE package to obtain variable importance estimations. We implemented three classes: Featurized Decision Tree (FDT), Random Fourier Features (RFF) and Neural Network (NN). For each class, mean square prediction error (MSPE, to compare out-of-sample predictive accuracy) and variable importance scores are provided. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd2cn_5VoeDO",
        "outputId": "cbd0642a-1893-45b6-f583-169f3f70ec88"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "#from tensorflow import keras\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Connect to your Google Drive, make sure there's a `GitHub` folder in `My Drive`.\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive/')\n",
        "\n",
        "#sys.path.append('/content/drive/My Drive/GitHub')\n",
        "# make sure you have installed the vie package\n",
        "import vie  \n",
        "\n",
        "# you can download all the data from \n",
        "# https://github.com/wdeng5120/featurized-decision-tree/tree/main/python/experiments/expr/datasets\n",
        "# and change the path to your local one\n",
        "#root_path = \"/content/drive/MyDrive\"\n",
        "data_path = os.path.join(\"./datasets/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkwznnCfp7Ov"
      },
      "source": [
        "## Define prepare_training_data function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_0QLVT0aolMd"
      },
      "outputs": [],
      "source": [
        "# @title prepare_training_data\n",
        "def prepare_training_data(data, n_obs):\n",
        "  df_train = data.head(n_obs)\n",
        "  df_test = data.tail(40)\n",
        "\n",
        "  x_train, y_train, f_train = df_train, df_train.pop(\"y\"), df_train.pop(\"f\")\n",
        "  x_test, y_test, f_test = df_test, df_test.pop(\"y\"), df_test.pop(\"f\")\n",
        "\n",
        "  x_train = x_train.to_numpy()\n",
        "  x_test = x_test.to_numpy()\n",
        "\n",
        "  y_train = y_train.to_numpy().reshape(-1, 1).ravel()\n",
        "  y_test = y_test.to_numpy().reshape(-1, 1).ravel()  \n",
        "  return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFFC5fGfqMfV"
      },
      "source": [
        "We will read data with the following argumets and prepare the training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKb3kifOqW3c",
        "outputId": "9831e129-79c0-4cfc-a166-d742cad38fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data 'rbf_n200_d25_i7.csv'\t"
          ]
        }
      ],
      "source": [
        "dataset_name = 'cont' # @param ['cat', 'cont', 'adult', 'heart', 'mi'] \n",
        "outcome_type = 'rbf' # @param ['linear', 'rbf', 'matern32', 'complex']\n",
        "n_obs = 200 # @param [100, 200, 500, 1000]\n",
        "dim_in = 25 # @param [25, 50, 100, 200]\n",
        "rep = 7 # @param \n",
        "\n",
        "data_file = f\"{outcome_type}_n{n_obs}_d{dim_in}_i{rep}.csv\"\n",
        "data_file_path = os.path.join(data_path, dataset_name, data_file)\n",
        "print(f\"Data '{data_file}'\", end='\\t', flush=True)  \n",
        "\n",
        "data = pd.read_csv(data_file_path, index_col=0)  \n",
        "x_train, y_train, x_test, y_test = prepare_training_data(data, n_obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fys3HIQwGhPd"
      },
      "source": [
        "Now let's go over these three models one-by-one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0LepBe0rDFt"
      },
      "source": [
        "## Featurized Decision Tree (FDT)\n",
        "\n",
        "There are a few parameters that we need to specify for FDT. \n",
        "\n",
        "- **`x_train`: array-like of shape (n_samples, n_features)** \n",
        "\n",
        "  The training input samples. \n",
        "\n",
        "- **`y_train`: array-like of shape (n_samples,)** \n",
        "\n",
        "  The target values (class labels in classification, real numbers in regression).\n",
        "\n",
        "- **`c`: float, default=1.0** \n",
        "\n",
        "  The smoothing parameter controling the similarity between our softmax approximation tree and the original decision tree. \n",
        "\n",
        "- **`sig2`: float, default=0.01** \n",
        "\n",
        "  The estimated variance of noise, which can be obtained from cross validation. \n",
        "\n",
        "- **`n_tree`: int, default=20**\n",
        "\n",
        "  The number of trees in the forest.\n",
        "\n",
        "- **`compute_psi`: bool, default=True**\n",
        "\n",
        "  Whether to compute variable importance scores. If False, the vector of variable importance scores is returned as zeros of shape (n_features,).\n",
        "\n",
        "- **`batch_size`: int, default=20**\n",
        "\n",
        "  Batch size for computing the variable importance scores. Only available if compute_psi=True.\n",
        "\n",
        "- **`n_samp`: int, default=100**\n",
        "\n",
        "  Number of the posterior samples of beta. Only available if compute_psi=True.\n",
        "\n",
        "- **`seed`: int, default=0**\n",
        "\n",
        "  Controls both the randomness of the bootstrapping of the samples used when building trees and the sampling of the features to consider when looking for the best split at each node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaYXiRZ5wNMX",
        "outputId": "7baf9ffd-d438-424b-cf87-05453cc51b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: psi_est_all: (100, 20, 20, 25), grad_train: (20, 25), psi_est: (25,)\n"
          ]
        }
      ],
      "source": [
        "fdt_out = vie.get_fdt_model(x_train, y_train, c=0.1, sig2=0.01, n_tree=20, \n",
        "                            compute_psi=True, batch_size=20, n_samp=10, seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUmM-s-Yv9VP"
      },
      "source": [
        "Here we set `n_sampe=10`, for the convenience of illustration. `fdt_out` has four returns. \n",
        "\n",
        "- **`psi_est`: ndarray of shape (n_features,)** \n",
        "\n",
        "  The vector of variable importance scores. An array of zeros if compute_psi=False.\n",
        "\n",
        "- **`f`: prediction function** \n",
        "\n",
        "  The prediction function with four parameters and returns the predicted values of shape (n_samples, n_tree).\n",
        "    - **`X`: array-like of shape (n_samples, n_features)** \n",
        "\n",
        "    The input samples. \n",
        "    - **`map_matrix`: array-like of shape (n_tree, 2*(n_leaf_nodes - 1), n_leaf_nodes)** \n",
        "\n",
        "    The mapping matrix maps each sample from the path to the leaf node.\n",
        "\n",
        "    - **`feature`: array-like of shape (n_tree, n_leaf_nodes - 1)**\n",
        "\n",
        "    Features used for splitting nodes.\n",
        "\n",
        "    - **`threshold`: array-like of shape (n_tree, n_leaf_nodes - 1)** \n",
        "\n",
        "    Threshold values.\n",
        "\n",
        "    - **`beta`: array-like of shape (n_tree, n_leaf_nodes)**\n",
        "\n",
        "    Posterior means of the coefficients for leaf nodes.\n",
        "  \n",
        "- **`grad_fs`: function to compute variable importance scores** \n",
        "\n",
        "  The function to compute variable importance scores of shape (n_samp, n_samples, n_tree, n_features) with four parameters: The first three are the same as the those in `f`, with the fourth as \n",
        "\n",
        "    - **`betas`: array-like of shape (n_tree, n_samp, n_leaf_nodes)**\n",
        "\n",
        "    Posterior samples of the coefficients for leaf nodes.\n",
        "\n",
        "- **`out_set`: dictionary containing five items: `map_matrix`, `feature`, `threshold`, `beta`, `betas`** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QrX3F3DJUMZ"
      },
      "source": [
        "Let's see the MSPE on testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPbowtwr2g4Y",
        "outputId": "e57747c3-d1db-460b-85ce-5230d423439d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.593397296777089"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f = fdt_out[1]\n",
        "map_matrix = fdt_out[3][\"map_matrix\"]\n",
        "feature = fdt_out[3][\"feature\"]\n",
        "threshold = fdt_out[3][\"threshold\"]\n",
        "beta = fdt_out[3][\"beta\"]\n",
        "pred_test = np.array(f(x_test, map_matrix, feature, threshold, beta))\n",
        "np.mean((y_test - np.mean(pred_test, 1)) ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kxXrQy0Qzaw"
      },
      "source": [
        "The first output of `fdt_out` is the vector of variable importance scores computed using `x_train`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W6wjD7x4RCkV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 20, 20, 25)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "psi_train = fdt_out[0]\n",
        "psi_train\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.imshow(psi_train[1])\n",
        "psi_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB3VD7M8Ra4l"
      },
      "source": [
        "We know the true variables that generated `y` are the first five ones. Therefore, we can calculate the auroc score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwodpGu_RZ7Y",
        "outputId": "938d80d8-5211-4b5a-d978-5cf64ac20999"
      },
      "outputs": [],
      "source": [
        "true = np.concatenate((np.repeat(1, 5), np.repeat(0, x_train.shape[1] - 5)))\n",
        "#roc_auc_score(true, psi_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26pgpDWkRz-F"
      },
      "source": [
        "We can also compute the variable importance scores computed using `x_test` and calculate the auroc score. Since the one obtained from `grad_fs` is of shape (n_samp, n_samples, n_tree, n_features). We take the mean across the first axes and take the median across different trees (for robustness, but can also use mean)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2bOZ8d-LQy3",
        "outputId": "e7cfee13-bafe-4a98-ce68-3b3e25642cf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grad_fs = fdt_out[2]\n",
        "betas = fdt_out[3][\"betas\"]\n",
        "psi_est = np.array(grad_fs(x_test, map_matrix, feature, threshold, betas))\n",
        "grad_train = np.mean(psi_est**2, axis=(0,1))\n",
        "psi_test = np.median(grad_train, axis=0)\n",
        "roc_auc_score(true, psi_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwqg2MtYsGqM"
      },
      "source": [
        "## Random Fourier Features (RFF)\n",
        "\n",
        "Next we see the performance of our variable importance measure applying to (approximated) kernel methods, Random Fourier Features. Here we set the number of features to be $O(\\sqrt{n}\\log(n))$ according to [Rudi, A. and Rosasco, L.](https://proceedings.neurips.cc/paper/2017/hash/61b1fb3f59e28c67f3925f3c79be81a1-Abstract.html). To select the length-scale parameter of the RBF kernel that RFF approximates to, we loop over a list of candidates and select the one with the smallest MSPE. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KMduXoPLsJmM"
      },
      "outputs": [],
      "source": [
        "n_rff = int(np.sqrt(n_obs) * np.log(n_obs)) + 1\n",
        "pred_mse_rff = []\n",
        "l_lst = [5.0, 10.0, 16.0, 23.0]\n",
        "for l in l_lst:\n",
        "    m = vie.rff(x_train, y_train, dim_hidden=n_rff, sig2=0.01, lengthscale=l, seed=0)\n",
        "    m.train()\n",
        "    pred = m.predict(x_test)[0]\n",
        "    pred_mse_rff.append(np.mean((pred - y_test) ** 2))\n",
        "\n",
        "l_best = l_lst[np.argmin(pred_mse_rff)]\n",
        "m = vie.rff(x_train, y_train, dim_hidden=n_rff, sig2=0.01, lengthscale=l_best, seed=0)\n",
        "m.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfuaDB1bZMqv"
      },
      "source": [
        "Similarly, we can compute the MSPE using `x_test`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxjhW4gxZl18",
        "outputId": "2d96110f-af9f-4114-d683-aac652671565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.1967065724486168"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_test = m.predict(x_test)[0]\n",
        "np.mean((y_test - pred_test) ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xoNwYwiZ9Q4"
      },
      "source": [
        "Compute and the variable importance scores using `x_train` and calculate the auroc score. Can also do this using `x_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swrfTCk9u-xc",
        "outputId": "5ce59b35-dc36-4c45-d9a8-845f6df32937"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.81"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "psi_train = m.estimate_psi(x_train)[0]\n",
        "roc_auc_score(true, psi_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1KlDxIWafhG",
        "outputId": "fbdc9b91-85b2-43af-fb1d-3c4508e403de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.05374935, 0.09295999, 0.00228801, 0.02916229, 0.00893562,\n",
              "       0.02350537, 0.01223522, 0.00875522, 0.00095611, 0.0028615 ,\n",
              "       0.00158964, 0.00312815, 0.00289245, 0.01179507, 0.00149384,\n",
              "       0.00064764, 0.00203501, 0.00327557, 0.00317923, 0.00255488,\n",
              "       0.00289723, 0.01099721, 0.00123574, 0.0012253 , 0.01066384])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "psi_test = m.estimate_psi(x_test)[0]\n",
        "roc_auc_score(true, psi_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYWKZ1KYvN0K"
      },
      "source": [
        "## Neural Network (NN)\n",
        "\n",
        "Finally, we see the performance of our variable importance measure applying to Neural Network. \n",
        "\n",
        "We use a one-hidden-layer NN with regularization imposed on the layer between the input and the hidden layer. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7WtTfBarvUh3"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3  # @param\n",
        "l1 = 1e2  # @param\n",
        "l2 = 1e2\n",
        "dim_hidden = 512  # @param\n",
        "outlier_mse_cutoff = [100] # remove outliers\n",
        "pred_mse_lst = [] # store the MSPE for each NN\n",
        "psi_lst = [] # store the variable importance scores for each NN\n",
        "batch_size = 20\n",
        "sig2 = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwMOHLAyc_a8"
      },
      "source": [
        "We repeat the model 5 times with different seeds. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bI1pnU2yxddL"
      },
      "outputs": [],
      "source": [
        "n_model = 5\n",
        "for i in range(n_model):\n",
        "    m = vie.get_nn_model(dim_in=dim_in, dim_hidden=dim_hidden,\n",
        "                         seed=i, lr=lr, l1=l1, l2=l2,\n",
        "                         outlier_mse_cutoff=outlier_mse_cutoff)\n",
        "\n",
        "    # Define callbacks.\n",
        "    early_stop_callback = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_robust_mse_100\", min_delta=1e-6, patience=25, verbose=0)\n",
        "    metrics_callback = vie.MetricsCallback(x_train=x_train,\n",
        "                                           x_test=x_test,\n",
        "                                           y_test=y_test,\n",
        "                                           outlier_mse_cutoff=outlier_mse_cutoff,\n",
        "                                           dim_in=dim_in)\n",
        "\n",
        "    m.fit(x_train, y_train, batch_size=32, epochs=500, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[early_stop_callback, metrics_callback],\n",
        "          verbose=0)\n",
        "\n",
        "    # Decide best epoch by MSPE.\n",
        "    mse_history = metrics_callback.history['y_mse_100']\n",
        "    psi_history = metrics_callback.history['psi']\n",
        "    best_epoch_mse = np.argmin(mse_history)\n",
        "    best_mse_by_mse = mse_history[best_epoch_mse]\n",
        "    best_psi_by_mse = psi_history[best_epoch_mse]\n",
        "    pred_mse_lst.append(best_mse_by_mse)\n",
        "    psi_lst.append(best_psi_by_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut2ec_1Syyrr",
        "outputId": "7e89ba0f-f9ca-4eb6-d1f1-f72ee313c6e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.902294902450946"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(pred_mse_lst) # MSPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRj8sIP7yky8",
        "outputId": "77636446-bc83-4097-eb26-35836b89f122"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.78"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "psi_train = np.mean(np.array(psi_lst), 0)\n",
        "roc_auc_score(true, psi_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl9xEaLnepb4"
      },
      "source": [
        "Unfortunately, unlike FDT and RFF, we cannot compute the variable importance scores using `x_test`. This is because during training, the model only computes the variable importance scores using `x_train`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNbmc8cGYWyV0W8NTn6cVNd",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "d59b506a0e703b59755888ed29552127d9b4544333d10d3ff144388b8386bf11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
